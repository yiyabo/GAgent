#!/usr/bin/env python3
"""
Agentå·¥ä½œæµç¨‹è·¯ç”±æ¨¡å—

ä¸“é—¨å¤„ç†Agentä»»åŠ¡ç¼–æ’çš„å®Œæ•´å·¥ä½œæµç¨‹ï¼š
æ„å›¾è¯†åˆ« â†’ ä»»åŠ¡åˆ†è§£ â†’ DAGç”Ÿæˆ â†’ ç”¨æˆ·ç¡®è®¤ â†’ æ‰§è¡Œè°ƒåº¦
"""

import logging
import time
import os
from pathlib import Path
from typing import Any, Dict, List, Optional
from fastapi import APIRouter, HTTPException
from pydantic import BaseModel

from ..services.planning.planning import propose_plan_service
from ..scheduler import bfs_schedule
from ..repository.tasks import default_repo
from ..llm import get_default_client
from ..utils.task_path_generator import get_task_file_path, ensure_task_directory

logger = logging.getLogger(__name__)
router = APIRouter(prefix="/agent", tags=["agent"])


class AgentRequest(BaseModel):
    """Agentè¯·æ±‚æ¨¡å‹"""
    goal: str
    context: Optional[Dict[str, Any]] = None
    user_preferences: Optional[Dict[str, Any]] = None


class TaskNode(BaseModel):
    """ä»»åŠ¡èŠ‚ç‚¹æ¨¡å‹"""
    id: int
    name: str
    task_type: str  # root, composite, atomic
    status: str
    parent_id: Optional[int] = None
    dependencies: List[int] = []
    depth: int
    estimated_time: Optional[str] = None


class AgentWorkflowResponse(BaseModel):
    """Agentå·¥ä½œæµç¨‹å“åº”"""
    workflow_id: str
    goal: str
    root_task_id: int
    dag_structure: List[TaskNode]
    execution_plan: List[Dict[str, Any]]
    user_actions: List[Dict[str, Any]]
    metadata: Dict[str, Any]


@router.post("/create-workflow", response_model=AgentWorkflowResponse)
async def create_agent_workflow(request: AgentRequest):
    """
    åˆ›å»ºå®Œæ•´çš„Agentå·¥ä½œæµç¨‹
    
    æµç¨‹ï¼š
    1. æ„å›¾åˆ†æå’Œç¡®è®¤
    2. ROOTä»»åŠ¡åˆ›å»º  
    3. é€’å½’åˆ†è§£ä¸ºCOMPOSITEå’ŒATOMICä»»åŠ¡
    4. ç”ŸæˆDAGç»“æ„
    5. åˆ›å»ºæ‰§è¡Œè®¡åˆ’
    6. è¿”å›ç”¨æˆ·ç¡®è®¤ç•Œé¢æ•°æ®
    """
    try:
        logger.info(f"ğŸš€ å¼€å§‹åˆ›å»ºAgentå·¥ä½œæµç¨‹: {request.goal}")
        
        # æ­¥éª¤1: ä½¿ç”¨LLMè¿›è¡Œæ„å›¾åˆ†æå’Œä»»åŠ¡åˆ†è§£
        logger.info("ğŸ“‹ æ­¥éª¤1: LLMé©±åŠ¨çš„ä»»åŠ¡åˆ†è§£")
        plan_result = propose_plan_service({
            "goal": request.goal,
            "title": f"Agentå·¥ä½œæµç¨‹: {request.goal[:50]}",
            "style": "hierarchical_decomposition", 
            "notes": "åˆ›å»ºå…·æœ‰æ˜ç¡®å±‚æ¬¡ç»“æ„çš„ä»»åŠ¡åˆ†è§£ï¼Œæ”¯æŒROOTâ†’COMPOSITEâ†’ATOMICçš„é€’å½’åˆ†è§£"
        })
        
        # æ­¥éª¤2: åˆ›å»ºROOTä»»åŠ¡
        logger.info("ğŸŒ³ æ­¥éª¤2: åˆ›å»ºROOTä»»åŠ¡")
        session_context = request.context or {}
        session_id = session_context.get("session_id")
        # ç»Ÿä¸€å·¥ä½œæµIDæ¥æºï¼šä¼˜å…ˆä½¿ç”¨å‰ç«¯/è°ƒç”¨æ–¹æä¾›çš„workflow_idï¼Œå¦åˆ™ç”Ÿæˆä¸€æ¬¡å¹¶è´¯ç©¿ä½¿ç”¨
        workflow_id = session_context.get("workflow_id")
        if not workflow_id:
            workflow_id = f"workflow_{int(time.time())}"

        # ä½¿ç”¨LLMç”Ÿæˆçš„æ ‡é¢˜ä½œä¸ºROOTåç§°ï¼ˆä¸åŠ äººå·¥å‰ç¼€ï¼‰
        root_task_name = plan_result['title']
        root_task_id = default_repo.create_task(
            name=root_task_name,
            status="pending",
            priority=1,
            task_type="root",
            session_id=session_id,
            workflow_id=workflow_id,
        )
        # ä¸ºROOTåˆ›å»ºç»“æœç›®å½•ä¸å ä½æ–‡ä»¶ï¼ˆsummary.md, paper.mdï¼‰
        try:
            root_task_info = default_repo.get_task_info(root_task_id)
            root_dir = get_task_file_path(root_task_info, default_repo)  # results/<root_name>/
            if ensure_task_directory(root_dir):
                summary_path = os.path.join(root_dir, "summary.md")
                paper_path = os.path.join(root_dir, "paper.md")
                if not os.path.exists(summary_path):
                    with open(summary_path, "w", encoding="utf-8") as f:
                        f.write(f"# {root_task_name} â€” ç»¼åˆæ€»ç»“\n\næ­¤æ–‡æ¡£å°†èšåˆå„ä¸ª COMPOSITE çš„ summary.md ä»¥å½¢æˆæœ€ç»ˆçš„ç ”ç©¶æ€»ç»“ã€‚\n")
                if not os.path.exists(paper_path):
                    with open(paper_path, "w", encoding="utf-8") as f:
                        f.write(f"# {root_task_name} â€” è®ºæ–‡è‰ç¨¿\n\nè¯¥æ–‡æ¡£ç”±ä¸“ç”¨LLMæ’°å†™ï¼Œå°†å‚è€ƒæ‰€æœ‰ ATOMIC æ–‡æ¡£ä¸å‚è€ƒè®ºæ–‡æ¥ç”Ÿæˆã€‚\n")
        except Exception as e:
            logger.warning(f"Failed to bootstrap ROOT result folder: {e}")
        
        # æ­¥éª¤3: åˆ›å»ºç®€åŒ–çš„ä»»åŠ¡å±‚æ¬¡ç»“æ„
        logger.info("ğŸ”„ æ­¥éª¤3: åˆ›å»ºä»»åŠ¡å±‚æ¬¡")
        composite_tasks = []
        
        # åˆ›å»ºCOMPOSITEä»»åŠ¡ï¼ˆç›´æ¥ä½œä¸ºå¯æ‰§è¡Œä»»åŠ¡ï¼‰ï¼Œåç§°ç›´æ¥ä½¿ç”¨LLMç”Ÿæˆçš„å­ä»»åŠ¡å
        for i, task in enumerate(plan_result['tasks']):
            composite_name = task['name']
            composite_task_id = default_repo.create_task(
                name=composite_name,
                status="pending", 
                priority=i + 1,
                parent_id=root_task_id,
                root_id=root_task_id,  # â­ å…³é”®ï¼šè®¾ç½®root_idç”¨äºå±‚çº§è·¯å¾„
                task_type="composite",
                session_id=session_id,  # â­ å…³é”®ï¼šä¼ é€’session_id
                workflow_id=workflow_id
            )
            # ä¸ºCOMPOSITEåˆ›å»ºç›®å½•ä¸å ä½summary.md
            try:
                comp_info = default_repo.get_task_info(composite_task_id)
                comp_dir = get_task_file_path(comp_info, default_repo)  # results/<root>/<composite>/
                if ensure_task_directory(comp_dir):
                    comp_summary_path = os.path.join(comp_dir, "summary.md")
                    if not os.path.exists(comp_summary_path):
                        with open(comp_summary_path, "w", encoding="utf-8") as f:
                            f.write(f"# {composite_name} â€” é˜¶æ®µæ€»ç»“\n\næ­¤æ–‡æ¡£å°†èšåˆè¯¥ COMPOSITE ä¸‹æ‰€æœ‰ ATOMIC çš„è¾“å‡ºï¼Œä»¥å½¢æˆé˜¶æ®µæ€»ç»“ã€‚\n")
            except Exception as e:
                logger.warning(f"Failed to bootstrap COMPOSITE folder for task {composite_task_id}: {e}")
            composite_tasks.append({
                "id": composite_task_id,
                "name": task['name'],
                "prompt": task['prompt'],
                "parent_id": root_task_id
            })
        
        # æ­¥éª¤4: ç®€åŒ–ä¾èµ–å…³ç³»ï¼ˆé¡ºåºæ‰§è¡Œï¼‰
        logger.info("ğŸ”— æ­¥éª¤4: æ„å»ºç®€åŒ–ä¾èµ–å…³ç³»")
        dependencies = {}
        for i, task in enumerate(composite_tasks):
            if i > 0:
                # æ¯ä¸ªä»»åŠ¡ä¾èµ–å‰ä¸€ä¸ªä»»åŠ¡
                dependencies[task["id"]] = [composite_tasks[i-1]["id"]]
            else:
                dependencies[task["id"]] = []
        
        # æ­¥éª¤5: ç”ŸæˆDAGç»“æ„ï¼ˆç®€åŒ–ç‰ˆï¼‰
        logger.info("ğŸ“Š æ­¥éª¤5: ç”ŸæˆDAGç»“æ„")
        dag_structure = []
        
        # æ·»åŠ ROOTä»»åŠ¡
        dag_structure.append(TaskNode(
            id=root_task_id,
            name=root_task_name,
            task_type="root",
            status="pending",
            parent_id=None,
            dependencies=[],
            depth=0
        ))
        
        # æ·»åŠ COMPOSITEä»»åŠ¡
        for task in composite_tasks:
            dag_structure.append(TaskNode(
                id=task["id"],
                name=task["name"],
                task_type="composite",
                status="pending",
                parent_id=root_task_id,
                dependencies=dependencies.get(task["id"], []),
                depth=1
            ))
        
        # æ­¥éª¤6: ç”Ÿæˆç®€åŒ–æ‰§è¡Œè®¡åˆ’
        logger.info("ğŸ“… æ­¥éª¤6: ç”Ÿæˆæ‰§è¡Œè®¡åˆ’")
        execution_plan = []
        
        for i, task in enumerate(composite_tasks):
            execution_plan.append({
                "task_id": task["id"],
                "name": task["name"],
                "execution_order": i + 1,
                "prerequisites": dependencies.get(task["id"], []),
                "estimated_duration": "30-60åˆ†é’Ÿ"
            })
        
        # æ³¨æ„ï¼šworkflow_id å·²åœ¨ä¸Šæ–¹ç¡®å®šï¼Œå¿…é¡»ä¸å­˜å…¥DBçš„ä¸€è‡´
        
        return AgentWorkflowResponse(
            workflow_id=workflow_id,
            goal=request.goal,
            root_task_id=root_task_id,
            dag_structure=dag_structure,
            execution_plan=execution_plan,
            user_actions=[
                {"type": "approve_workflow", "label": "ç¡®è®¤å¹¶å¼€å§‹æ‰§è¡Œ"},
                {"type": "modify_tasks", "label": "ä¿®æ”¹ä»»åŠ¡ç»“æ„"},
                {"type": "adjust_dependencies", "label": "è°ƒæ•´ä¾èµ–å…³ç³»"},
                {"type": "cancel_workflow", "label": "å–æ¶ˆå·¥ä½œæµç¨‹"}
            ],
            metadata={
                "total_tasks": len(dag_structure),
                "composite_tasks": len([t for t in dag_structure if t.task_type == "composite"]),
                "estimated_completion": "2-4å°æ—¶",
                "created_at": time.time()
            }
        )
        
    except Exception as e:
        logger.error(f"âŒ Agentå·¥ä½œæµç¨‹åˆ›å»ºå¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"å·¥ä½œæµç¨‹åˆ›å»ºå¤±è´¥: {str(e)}")


# ç®€åŒ–ç‰ˆæœ¬ - ç§»é™¤å¤æ‚çš„LLMè°ƒç”¨é“¾ï¼Œé¿å…çº§è”å¤±è´¥


@router.get("/workflow/{workflow_id}")
async def get_workflow_status(workflow_id: str):
    """è·å–å·¥ä½œæµç¨‹çŠ¶æ€"""
    # TODO: å®ç°å·¥ä½œæµç¨‹çŠ¶æ€æŸ¥è¯¢
    pass


@router.post("/workflow/{workflow_id}/approve")
async def approve_workflow(workflow_id: str):
    """ç”¨æˆ·ç¡®è®¤å¹¶å¼€å§‹æ‰§è¡Œå·¥ä½œæµç¨‹"""
    # TODO: å®ç°å·¥ä½œæµç¨‹ç¡®è®¤å’Œå¯åŠ¨
    pass


@router.post("/workflow/{workflow_id}/modify")
async def modify_workflow(workflow_id: str, modifications: Dict[str, Any]):
    """ç”¨æˆ·ä¿®æ”¹å·¥ä½œæµç¨‹"""
    # TODO: å®ç°å·¥ä½œæµç¨‹ä¿®æ”¹
    pass
