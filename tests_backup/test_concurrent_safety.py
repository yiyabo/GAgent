#!/usr/bin/env python3
"""
å¹¶å‘å®‰å…¨æµ‹è¯• - ç®€åŒ–ç‰ˆæœ¬

ä¸“é—¨æµ‹è¯•å…³é”®çš„å¹¶å‘å®‰å…¨é—®é¢˜ä¿®å¤ã€‚
"""

import os
import tempfile
import threading
import time
from concurrent.futures import ThreadPoolExecutor

import pytest

# è®¾ç½®æ­£ç¡®çš„æ¨¡æ‹Ÿæ¨¡å¼ç¯å¢ƒå˜é‡
os.environ["LLM_MOCK"] = "1"
os.environ["EMBEDDING_CACHE_PERSISTENT"] = "0"  # ç¦ç”¨æŒä¹…åŒ–ç¼“å­˜é¿å…æ–‡ä»¶è­¦å‘Š


def test_thread_safe_singleton():
    """æµ‹è¯•çº¿ç¨‹å®‰å…¨çš„å•ä¾‹æ¨¡å¼"""
    from app.services.thread_safe_embeddings import get_thread_safe_embeddings_service

    services = []
    errors = []

    def get_service():
        try:
            service = get_thread_safe_embeddings_service()
            services.append(service)
        except Exception as e:
            errors.append(e)

    # å¹¶å‘è·å–æœåŠ¡å®ä¾‹
    with ThreadPoolExecutor(max_workers=10) as executor:
        futures = [executor.submit(get_service) for _ in range(10)]
        for future in futures:
            future.result()

    # éªŒè¯
    assert len(errors) == 0, f"Errors: {errors}"
    assert len(services) == 10
    # æ‰€æœ‰å®ä¾‹åº”è¯¥æ˜¯åŒä¸€ä¸ªå¯¹è±¡
    assert all(service is services[0] for service in services)


def test_thread_safe_cache():
    """æµ‹è¯•çº¿ç¨‹å®‰å…¨çš„ç¼“å­˜æ“ä½œ"""
    from app.services.thread_safe_cache import ThreadSafeEmbeddingCache

    # ä½¿ç”¨ä¸´æ—¶æ•°æ®åº“ï¼Œå¹¶ç¡®ä¿æ­£ç¡®å…³é—­è¿æ¥
    with tempfile.TemporaryDirectory() as temp_dir:
        cache = ThreadSafeEmbeddingCache(cache_size=100, enable_persistent=True)
        cache.cache_db_path = os.path.join(temp_dir, "test_cache.db")
        cache._init_persistent_cache()

        try:
            errors = []

            def concurrent_cache_ops(thread_id: int):
                try:
                    # å†™å…¥æ“ä½œ
                    for i in range(10):
                        text = f"test_{thread_id}_{i}"
                        embedding = [float(j) for j in range(10)]
                        cache.put(text, embedding)

                    # è¯»å–æ“ä½œ
                    for i in range(10):
                        text = f"test_{thread_id}_{i}"
                        result = cache.get(text)
                        assert result is not None or True  # å…è®¸ç¼“å­˜æœªå‘½ä¸­

                except Exception as e:
                    errors.append(f"Thread {thread_id}: {e}")

            # å¹¶å‘æ‰§è¡Œç¼“å­˜æ“ä½œ
            with ThreadPoolExecutor(max_workers=5) as executor:
                futures = [executor.submit(concurrent_cache_ops, i) for i in range(5)]
                for future in futures:
                    future.result()

            # éªŒè¯
            assert len(errors) == 0, f"Concurrent cache errors: {errors}"

            # è·å–ç»Ÿè®¡ä¿¡æ¯éªŒè¯ç¼“å­˜æ­£å¸¸å·¥ä½œ
            stats = cache.get_stats()
            assert stats["memory_cache_size"] >= 0

        finally:
            # ç¡®ä¿å…³é—­ç¼“å­˜è¿æ¥ï¼Œé¿å…ResourceWarning
            cache.shutdown()


def test_concurrent_embedding_generation():
    """æµ‹è¯•å¹¶å‘åµŒå…¥å‘é‡ç”Ÿæˆ"""
    from app.services.thread_safe_embeddings import get_thread_safe_embeddings_service

    service = get_thread_safe_embeddings_service()
    results = []
    errors = []

    def generate_embeddings(thread_id: int):
        try:
            texts = [f"concurrent_test_{thread_id}_{i}" for i in range(3)]
            embeddings = service.get_embeddings(texts)
            results.append((thread_id, len(embeddings)))

            # éªŒè¯ç»“æœæ ¼å¼
            assert len(embeddings) == len(texts)
            for embedding in embeddings:
                assert isinstance(embedding, list)

        except Exception as e:
            errors.append(f"Thread {thread_id}: {e}")

    # å¹¶å‘ç”ŸæˆåµŒå…¥å‘é‡
    with ThreadPoolExecutor(max_workers=5) as executor:
        futures = [executor.submit(generate_embeddings, i) for i in range(5)]
        for future in futures:
            future.result()

    # éªŒè¯
    assert len(errors) == 0, f"Concurrent generation errors: {errors}"
    assert len(results) == 5
    # æ‰€æœ‰ç»“æœåº”è¯¥æœ‰æ­£ç¡®çš„åµŒå…¥å‘é‡æ•°é‡
    for thread_id, embedding_count in results:
        assert embedding_count == 3


def test_async_task_safety():
    """æµ‹è¯•å¼‚æ­¥ä»»åŠ¡çš„çº¿ç¨‹å®‰å…¨æ€§"""
    from app.services.thread_safe_embeddings import get_thread_safe_embeddings_service

    service = get_thread_safe_embeddings_service()
    futures = []
    errors = []

    def submit_async_tasks(thread_id: int):
        try:
            for i in range(3):
                text = f"async_test_{thread_id}_{i}"
                future = service.get_single_embedding_async(text)
                futures.append(future)
        except Exception as e:
            errors.append(f"Thread {thread_id}: {e}")

    # å¹¶å‘æäº¤å¼‚æ­¥ä»»åŠ¡
    with ThreadPoolExecutor(max_workers=3) as executor:
        submit_futures = [executor.submit(submit_async_tasks, i) for i in range(3)]
        for future in submit_futures:
            future.result()

    # ç­‰å¾…æ‰€æœ‰å¼‚æ­¥ä»»åŠ¡å®Œæˆ
    for future in futures:
        try:
            result = future.result(timeout=10)
            assert isinstance(result, list)
        except Exception as e:
            errors.append(f"Async task error: {e}")

    # éªŒè¯
    assert len(errors) == 0, f"Async task errors: {errors}"
    assert len(futures) == 9  # 3 threads * 3 tasks each

    # æ£€æŸ¥æœåŠ¡çŠ¶æ€
    status = service.get_background_task_status()
    assert "thread_safe" in status
    assert status["thread_safe"] == True


if __name__ == "__main__":
    print("Running concurrent safety tests...")

    try:
        test_thread_safe_singleton()
        print("âœ“ Thread-safe singleton test passed")

        test_thread_safe_cache()
        print("âœ“ Thread-safe cache test passed")

        test_concurrent_embedding_generation()
        print("âœ“ Concurrent embedding generation test passed")

        test_async_task_safety()
        print("âœ“ Async task safety test passed")

        print("\nğŸ‰ All concurrent safety tests passed!")

    except Exception as e:
        print(f"\nâŒ Test failed: {e}")
        import traceback

        traceback.print_exc()
        raise
