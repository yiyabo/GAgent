"""
Smart Tool Router

This module provides intelligent routing capabilities to analyze user requests
and automatically select the most appropriate tools.
"""

import asyncio
import json
import logging
import os
import re
from typing import Any, Dict, List, Optional, Tuple

from .integration import get_llm_integration
from .tools import get_tool_registry

logger = logging.getLogger(__name__)


class SmartToolRouter:
    """Intelligent router for tool selection"""

    def __init__(self):
        self.tool_registry = get_tool_registry()
        self.llm_integration = None
        # Use unified LLM client instead of direct API calls
        try:
            from app.services.foundation.settings import get_settings
            self.settings = get_settings()
        except Exception:
            self.settings = None

    async def initialize(self) -> None:
        """Initialize the router"""
        from .integration import get_llm_integration

        self.llm_integration = await get_llm_integration()

    async def _call_llm_api(self, prompt: str, max_retries: int = 3) -> str:
        """Call unified LLM API (supports GLM, QWEN, etc.) for intelligent routing"""
        last_error = None
        
        for attempt in range(max_retries):
            try:
                # Use unified LLM client from app.llm
                from app.llm import get_default_client
                import asyncio
                
                client = get_default_client()
                provider = client.provider
                
                # Run sync client.chat in executor to avoid blocking
                loop = asyncio.get_event_loop()
                content = await loop.run_in_executor(None, client.chat, prompt)
                
                # Validate response quality
                if self._validate_api_response(content):
                    logger.info(f"âœ… {provider.upper()} APIæˆåŠŸ (å°è¯• {attempt + 1}/{max_retries})")
                    return content
                else:
                    logger.warning(f"âš ï¸ {provider.upper()} APIå“åº”è´¨é‡ä¸ä½³ (å°è¯• {attempt + 1})")
                    
            except asyncio.TimeoutError:
                logger.warning(f"â±ï¸ LLM APIè¶…æ—¶ (å°è¯• {attempt + 1}/{max_retries})")
                last_error = "Request timeout"
            except Exception as e:
                logger.error(f"LLM APIè°ƒç”¨å¤±è´¥ (å°è¯• {attempt + 1}): {e}")
                last_error = str(e)
                
                # Brief delay before retry
                if attempt < max_retries - 1:
                    await asyncio.sleep(1)

        logger.error(f"âŒ LLM APIæ‰€æœ‰é‡è¯•å¤±è´¥: {last_error}")
        return ""
        
    def _validate_api_response(self, content: str) -> bool:
        """Validate API response quality"""
        if not content or len(content.strip()) < 10:
            return False
            
        # Check for common error indicators
        error_indicators = ["error", "failed", "unable", "cannot", "sorry"]
        content_lower = content.lower()
        
        # If response is too short and contains error indicators, it's likely not useful
        if len(content) < 50 and any(indicator in content_lower for indicator in error_indicators):
            return False
            
        return True

    async def route_request(self, user_request: str, context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        Route user request using pure LLM intelligence

        Args:
            user_request: User's natural language request
            context: Additional context information

        Returns:
            Dict containing routing decision and tool calls
        """
        if not self.llm_integration:
            await self.initialize()

        logger.info("Using pure LLM routing for maximum intelligence")

        # Use enhanced LLM analysis for everything
        routing_result = await self._enhanced_llm_routing(user_request, context)

        if not routing_result:
            logger.error("LLM routing returned no result")
            # ç§‘ç ”é¡¹ç›®è¦æ±‚ï¼šå³ä½¿å¤±è´¥ä¹Ÿä¸æ”¾å¼ƒï¼Œå°è¯•ç®€åŒ–åˆ†æ
            routing_result = await self._simplified_llm_routing(user_request, context)
            
        if not routing_result:
            raise ValueError("Complete LLM routing failure - all analysis methods exhausted")
            
        # ç§‘ç ”é¡¹ç›®è¦æ±‚ï¼šæ¥å—æ›´ä½çš„ç½®ä¿¡åº¦ï¼Œä½†è®°å½•è¯¦ç»†ä¿¡æ¯
        confidence = routing_result.get("confidence", 0.0)
        if confidence < 0.1:
            logger.warning(f"âš ï¸ æä½ç½®ä¿¡åº¦è·¯ç”±: {confidence}, ä½†ç§‘ç ”é¡¹ç›®è¦æ±‚ç»§ç»­å¤„ç†")
            # å¢å¼ºç½®ä¿¡åº¦è¯„ä¼°
            routing_result = await self._enhance_confidence(routing_result, user_request)

        return {
            "request": user_request,
            "analysis": routing_result,
            "tool_calls": routing_result.get("tool_calls", []),
            "confidence": routing_result.get("confidence", 0.0),
            "routing_method": "pure_llm",
            "execution_plan": routing_result.get("execution_plan", ""),
            "estimated_time": routing_result.get("estimated_time", "unknown"),
        }

    async def _enhanced_llm_routing(self, request: str, context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """Enhanced LLM-based routing with complete tool call generation"""
        try:
            # Get available tools with detailed information
            tools = self.tool_registry.list_tools()
            tool_details = []

            for tool in tools:
                tool_info = {
                    "name": tool.name,
                    "description": tool.description,
                    "category": tool.category,
                    "parameters": tool.parameters_schema,
                    "examples": tool.examples,
                }
                tool_details.append(tool_info)

            # Build comprehensive LLM prompt
            context_str = ""
            if context:
                context_str = f"\nä¸Šä¸‹æ–‡ä¿¡æ¯:\n{json.dumps(context, ensure_ascii=False, indent=2)}"

            prompt = f"""
ä½ æ˜¯ä¸€ä¸ªé«˜çº§AIå·¥å…·è·¯ç”±å™¨ï¼Œä¸“é—¨ä¸ºæ™ºèƒ½agentç³»ç»Ÿè®¾è®¡ã€‚ä½ éœ€è¦åˆ†æç”¨æˆ·è¯·æ±‚å¹¶ç”Ÿæˆå®Œæ•´çš„å·¥å…·æ‰§è¡Œè®¡åˆ’ã€‚

å¯ç”¨å·¥å…·è¯¦ç»†ä¿¡æ¯:
{json.dumps(tool_details, ensure_ascii=False, indent=2)}

ç”¨æˆ·è¯·æ±‚: {request}{context_str}

è¯·è¿›è¡Œæ·±åº¦åˆ†æå¹¶è¿”å›å®Œæ•´çš„è·¯ç”±å†³ç­–ã€‚æ³¨æ„:
1. ä»”ç»†åˆ†æç”¨æˆ·çš„çœŸå®æ„å›¾
2. é€‰æ‹©æœ€åˆé€‚çš„å·¥å…·ç»„åˆ
3. ä¸ºæ¯ä¸ªå·¥å…·æå–å‡†ç¡®çš„å‚æ•°
4. è€ƒè™‘å·¥å…·æ‰§è¡Œçš„å…ˆåé¡ºåº
5. å¦‚æœéœ€è¦å¤šä¸ªå·¥å…·åä½œï¼Œè¯·è§„åˆ’å¥½ä¾èµ–å…³ç³»

è¿”å›JSONæ ¼å¼:
{{
    "intent": "è¯¦ç»†çš„ç”¨æˆ·æ„å›¾åˆ†æ",
    "complexity": "simple|medium|complex",
    "tool_calls": [
        {{
            "tool_name": "å…·ä½“å·¥å…·å",
            "parameters": {{"å‚æ•°å": "å‚æ•°å€¼"}},
            "reasoning": "é€‰æ‹©æ­¤å·¥å…·å’Œå‚æ•°çš„è¯¦ç»†ç†ç”±",
            "execution_order": 1
        }}
    ],
    "execution_plan": "æ•´ä½“æ‰§è¡Œè®¡åˆ’æè¿°",
    "estimated_time": "é¢„ä¼°æ‰§è¡Œæ—¶é—´",
    "confidence": 0.0åˆ°1.0ä¹‹é—´çš„ç½®ä¿¡åº¦,
    "reasoning": "å®Œæ•´çš„åˆ†ææ¨ç†è¿‡ç¨‹"
}}

åªè¿”å›JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚ç¡®ä¿å‚æ•°å®Œæ•´ä¸”ç¬¦åˆå·¥å…·çš„schemaè¦æ±‚ã€‚
"""

            # Call GLM API
            llm_response = await self._call_llm_api(prompt)

            if not llm_response:
                return {"confidence": 0.0, "error": "LLM call failed"}

            # Parse LLM response
            try:
                # Clean response
                cleaned_response = llm_response.strip()
                if cleaned_response.startswith("```json"):
                    cleaned_response = cleaned_response[7:]
                if cleaned_response.endswith("```"):
                    cleaned_response = cleaned_response[:-3]
                cleaned_response = cleaned_response.strip()

                analysis = json.loads(cleaned_response)

                # Validate and normalize confidence
                analysis["confidence"] = min(max(analysis.get("confidence", 0.0), 0.0), 1.0)

                # Ensure tool_calls exist and are valid
                if "tool_calls" not in analysis:
                    analysis["tool_calls"] = []

                # Sort tool calls by execution order if specified
                if analysis["tool_calls"]:
                    analysis["tool_calls"].sort(key=lambda x: x.get("execution_order", 999))

                return analysis

            except json.JSONDecodeError as e:
                logger.error(f"Failed to parse LLM response: {e}")
                logger.error(f"Original LLM response: {llm_response}")
                return {"confidence": 0.0, "error": "JSON parse failed"}

        except Exception as e:
            logger.error(f"Enhanced LLM routing failed: {e}")
            return {"confidence": 0.0, "error": str(e)}

    async def _simplified_llm_routing(self, request: str, context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """ç®€åŒ–çš„LLMè·¯ç”± - å½“æ ‡å‡†è·¯ç”±å¤±è´¥æ—¶ä½¿ç”¨"""
        try:
            logger.info("ğŸ”„ å¯ç”¨ç®€åŒ–LLMè·¯ç”±åˆ†æ")
            
            tools = self.tool_registry.list_tools()
            tool_names = [tool.name for tool in tools]
            
            # ç®€åŒ–çš„æç¤ºï¼Œä¸“æ³¨äºå·¥å…·é€‰æ‹©
            prompt = f"""
ç”¨æˆ·è¯·æ±‚: {request}

å¯ç”¨å·¥å…·: {', '.join(tool_names)}

è¯·ç®€å•åˆ†æç”¨æˆ·æ„å›¾å¹¶é€‰æ‹©æœ€åˆé€‚çš„å·¥å…·ã€‚è¿”å›JSON:
{{
    "intent": "ç”¨æˆ·æ„å›¾ç®€è¿°",
    "tool_calls": [{{"tool_name": "é€‰æ‹©çš„å·¥å…·", "parameters": {{}}, "reasoning": "é€‰æ‹©ç†ç”±"}}],
    "confidence": ç½®ä¿¡åº¦(0-1)
}}

åªè¿”å›JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚
"""
            
            llm_response = await self._call_llm_api(prompt)
            
            if not llm_response:
                return {"confidence": 0.0, "error": "Simplified LLM routing failed"}
                
            try:
                cleaned_response = llm_response.strip()
                if cleaned_response.startswith("```json"):
                    cleaned_response = cleaned_response[7:]
                if cleaned_response.endswith("```"):
                    cleaned_response = cleaned_response[:-3]
                cleaned_response = cleaned_response.strip()

                analysis = json.loads(cleaned_response)
                analysis["confidence"] = max(analysis.get("confidence", 0.0), 0.1)  # æœ€ä½ä¿è¯ç½®ä¿¡åº¦
                
                return analysis
                
            except json.JSONDecodeError as e:
                logger.error(f"ç®€åŒ–è·¯ç”±JSONè§£æå¤±è´¥: {e}")
                return {"confidence": 0.0, "error": "JSON parse failed in simplified routing"}
                
        except Exception as e:
            logger.error(f"ç®€åŒ–LLMè·¯ç”±å¤±è´¥: {e}")
            return {"confidence": 0.0, "error": str(e)}

    async def _enhance_confidence(self, routing_result: Dict[str, Any], user_request: str) -> Dict[str, Any]:
        """å¢å¼ºç½®ä¿¡åº¦è¯„ä¼°"""
        try:
            logger.info("ğŸ”¬ å¯ç”¨ç½®ä¿¡åº¦å¢å¼ºåˆ†æ")
            
            # åŸºäºå¤šä¸ªå› ç´ é‡æ–°è¯„ä¼°ç½®ä¿¡åº¦
            confidence_factors = []
            
            # å› ç´ 1: å·¥å…·è°ƒç”¨æ˜ç¡®æ€§
            tool_calls = routing_result.get("tool_calls", [])
            if tool_calls and len(tool_calls) > 0:
                confidence_factors.append(0.3)
                
            # å› ç´ 2: æ„å›¾æè¿°è¯¦ç»†ç¨‹åº¦
            intent = routing_result.get("intent", "")
            if intent and len(intent) > 20:
                confidence_factors.append(0.2)
                
            # å› ç´ 3: æ‰§è¡Œè®¡åˆ’å­˜åœ¨æ€§
            execution_plan = routing_result.get("execution_plan", "")
            if execution_plan:
                confidence_factors.append(0.2)
                
            # å› ç´ 4: æ¨ç†è¿‡ç¨‹å­˜åœ¨æ€§
            reasoning = routing_result.get("reasoning", "")
            if reasoning and len(reasoning) > 30:
                confidence_factors.append(0.2)
                
            # å› ç´ 5: ç”¨æˆ·è¯·æ±‚å¤æ‚åº¦é€‚é…
            request_complexity = len(user_request.split())
            if request_complexity <= 10:  # ç®€å•è¯·æ±‚æ›´å®¹æ˜“ç†è§£
                confidence_factors.append(0.1)
                
            # è®¡ç®—å¢å¼ºåçš„ç½®ä¿¡åº¦
            base_confidence = routing_result.get("confidence", 0.0)
            enhancement_boost = sum(confidence_factors)
            new_confidence = min(base_confidence + enhancement_boost, 0.95)
            
            routing_result["confidence"] = new_confidence
            routing_result["confidence_enhancement"] = {
                "original": base_confidence,
                "factors": confidence_factors,
                "enhanced": new_confidence
            }
            
            logger.info(f"ğŸ¯ ç½®ä¿¡åº¦å¢å¼º: {base_confidence:.2f} â†’ {new_confidence:.2f}")
            
            return routing_result
            
        except Exception as e:
            logger.error(f"ç½®ä¿¡åº¦å¢å¼ºå¤±è´¥: {e}")
            # è¿”å›åŸå§‹ç»“æœ
            return routing_result


# Global router instance
_smart_router = SmartToolRouter()


async def get_smart_router() -> SmartToolRouter:
    """Get the global smart router instance"""
    if not _smart_router.llm_integration:
        await _smart_router.initialize()
    return _smart_router


async def route_user_request(request: str, context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
    """Convenience function to route user requests"""
    router = await get_smart_router()
    return await router.route_request(request, context)
