#!/usr/bin/env python3
"""
çº¿ç¨‹å®‰å…¨æµ‹è¯•æ¨¡å—

ä¸“é—¨æµ‹è¯•åµŒå…¥å‘é‡æœåŠ¡çš„å¹¶å‘å®‰å…¨æ€§ï¼ŒåŒ…æ‹¬ï¼š
1. å•ä¾‹æ¨¡å¼çš„ç«æ€æ¡ä»¶æµ‹è¯•
2. ç¼“å­˜æ“ä½œçš„çº¿ç¨‹å®‰å…¨æµ‹è¯•  
3. å¼‚æ­¥ä»»åŠ¡ç®¡ç†çš„å¹¶å‘æµ‹è¯•
4. é«˜å¹¶å‘è´Ÿè½½æµ‹è¯•
"""

import pytest
import threading
import time
import random
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import List, Dict, Any

# å¯¼å…¥çº¿ç¨‹å®‰å…¨çš„æœåŠ¡
from app.services.thread_safe_embeddings import get_thread_safe_embeddings_service
from app.services.thread_safe_cache import get_thread_safe_embedding_cache


class TestThreadSafetyEmbeddings:
    """çº¿ç¨‹å®‰å…¨åµŒå…¥å‘é‡æœåŠ¡æµ‹è¯•"""
    
    def test_singleton_thread_safety(self):
        """æµ‹è¯•å•ä¾‹æ¨¡å¼çš„çº¿ç¨‹å®‰å…¨æ€§"""
        services = []
        errors = []
        
        def get_service():
            try:
                service = get_thread_safe_embeddings_service()
                services.append(service)
            except Exception as e:
                errors.append(e)
        
        # åˆ›å»ºå¤šä¸ªçº¿ç¨‹åŒæ—¶è·å–å•ä¾‹
        threads = []
        for _ in range(20):
            thread = threading.Thread(target=get_service)
            threads.append(thread)
        
        # åŒæ—¶å¯åŠ¨æ‰€æœ‰çº¿ç¨‹
        for thread in threads:
            thread.start()
        
        # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
        for thread in threads:
            thread.join()
        
        # éªŒè¯ç»“æœ
        assert len(errors) == 0, f"Errors occurred: {errors}"
        assert len(services) == 20, "Not all threads got service instance"
        
        # éªŒè¯æ‰€æœ‰æœåŠ¡å®ä¾‹éƒ½æ˜¯åŒä¸€ä¸ªå¯¹è±¡
        first_service = services[0]
        for service in services[1:]:
            assert service is first_service, "Singleton pattern violated"
    
    def test_cache_concurrent_access(self):
        """æµ‹è¯•ç¼“å­˜çš„å¹¶å‘è®¿é—®å®‰å…¨æ€§"""
        cache = get_thread_safe_embedding_cache()
        
        # æµ‹è¯•æ•°æ®
        test_texts = [f"test_text_{i}" for i in range(100)]
        test_embeddings = [[random.random() for _ in range(10)] for _ in range(100)]
        
        errors = []
        read_results = []
        
        def concurrent_write():
            """å¹¶å‘å†™å…¥æµ‹è¯•"""
            try:
                for i in range(0, len(test_texts), 2):
                    cache.put(test_texts[i], test_embeddings[i])
            except Exception as e:
                errors.append(f"Write error: {e}")
        
        def concurrent_read():
            """å¹¶å‘è¯»å–æµ‹è¯•"""
            try:
                results = []
                for text in test_texts[1::2]:  # è¯»å–ä¸åŒçš„æ•°æ®é¿å…å†²çª
                    result = cache.get(text)
                    results.append(result)
                read_results.append(results)
            except Exception as e:
                errors.append(f"Read error: {e}")
        
        def concurrent_batch_operations():
            """å¹¶å‘æ‰¹é‡æ“ä½œæµ‹è¯•"""
            try:
                batch_texts = test_texts[50:60]
                batch_embeddings = test_embeddings[50:60]
                
                # æ‰¹é‡å†™å…¥
                cache.put_batch(batch_texts, batch_embeddings)
                
                # æ‰¹é‡è¯»å–
                results, misses = cache.get_batch(batch_texts)
                assert len(results) == len(batch_texts)
            except Exception as e:
                errors.append(f"Batch operation error: {e}")
        
        # åˆ›å»ºå¹¶å‘æµ‹è¯•
        with ThreadPoolExecutor(max_workers=10) as executor:
            futures = []
            
            # æäº¤å†™å…¥ä»»åŠ¡
            for _ in range(3):
                futures.append(executor.submit(concurrent_write))
            
            # æäº¤è¯»å–ä»»åŠ¡
            for _ in range(3):
                futures.append(executor.submit(concurrent_read))
            
            # æäº¤æ‰¹é‡æ“ä½œä»»åŠ¡
            for _ in range(2):
                futures.append(executor.submit(concurrent_batch_operations))
            
            # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
            for future in as_completed(futures):
                future.result()
        
        # éªŒè¯æ²¡æœ‰é”™è¯¯å‘ç”Ÿ
        assert len(errors) == 0, f"Concurrent cache access errors: {errors}"
    
    def test_concurrent_embedding_generation(self):
        """æµ‹è¯•å¹¶å‘åµŒå…¥å‘é‡ç”Ÿæˆ"""
        service = get_thread_safe_embeddings_service()
        
        # æµ‹è¯•æ•°æ®
        test_texts_sets = [
            [f"concurrent_test_{i}_{j}" for j in range(5)]
            for i in range(10)
        ]
        
        results = []
        errors = []
        
        def generate_embeddings(texts: List[str]):
            """ç”ŸæˆåµŒå…¥å‘é‡çš„ä»»åŠ¡"""
            try:
                embeddings = service.get_embeddings(texts)
                results.append((texts, embeddings))
                
                # éªŒè¯ç»“æœå®Œæ•´æ€§
                assert len(embeddings) == len(texts), "Result count mismatch"
                
                for embedding in embeddings:
                    assert isinstance(embedding, list), "Invalid embedding format"
                    
            except Exception as e:
                errors.append(f"Embedding generation error: {e}")
        
        # å¹¶å‘æ‰§è¡Œå¤šä¸ªåµŒå…¥å‘é‡ç”Ÿæˆä»»åŠ¡
        with ThreadPoolExecutor(max_workers=8) as executor:
            futures = []
            for texts in test_texts_sets:
                futures.append(executor.submit(generate_embeddings, texts))
            
            # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
            for future in as_completed(futures):
                future.result()
        
        # éªŒè¯ç»“æœ
        assert len(errors) == 0, f"Concurrent embedding generation errors: {errors}"
        assert len(results) == len(test_texts_sets), "Not all tasks completed"
    
    def test_async_task_management_thread_safety(self):
        """æµ‹è¯•å¼‚æ­¥ä»»åŠ¡ç®¡ç†çš„çº¿ç¨‹å®‰å…¨æ€§"""
        service = get_thread_safe_embeddings_service()
        
        completed_callbacks = []
        errors = []
        futures = []
        
        def completion_callback(embeddings):
            """å®Œæˆå›è°ƒ"""
            completed_callbacks.append(len(embeddings))
        
        def error_callback(embeddings, error=None):
            """é”™è¯¯å›è°ƒ"""
            if error:
                errors.append(error)
        
        def submit_async_tasks():
            """æäº¤å¼‚æ­¥ä»»åŠ¡"""
            try:
                for i in range(5):
                    texts = [f"async_test_{threading.get_ident()}_{i}_{j}" for j in range(3)]
                    future = service.get_embeddings_async(texts, completion_callback)
                    futures.append(future)
            except Exception as e:
                errors.append(f"Task submission error: {e}")
        
        # å¹¶å‘æäº¤å¼‚æ­¥ä»»åŠ¡
        with ThreadPoolExecutor(max_workers=5) as executor:
            submit_futures = []
            for _ in range(5):
                submit_futures.append(executor.submit(submit_async_tasks))
            
            # ç­‰å¾…æ‰€æœ‰æäº¤å®Œæˆ
            for future in as_completed(submit_futures):
                future.result()
        
        # ç­‰å¾…æ‰€æœ‰å¼‚æ­¥ä»»åŠ¡å®Œæˆ
        for future in futures:
            try:
                future.result(timeout=30)
            except Exception as e:
                errors.append(f"Async task error: {e}")
        
        # éªŒè¯ç»“æœ
        assert len(errors) == 0, f"Async task management errors: {errors}"
        
        # æ£€æŸ¥ä»»åŠ¡çŠ¶æ€
        status = service.get_background_task_status()
        assert status['thread_safe'] == True, "Service should be thread-safe"
    
    def test_high_concurrency_stress(self):
        """é«˜å¹¶å‘å‹åŠ›æµ‹è¯•"""
        service = get_thread_safe_embeddings_service()
        cache = get_thread_safe_embedding_cache()
        
        # æµ‹è¯•å‚æ•°
        num_threads = 20
        operations_per_thread = 10
        
        start_time = time.time()
        errors = []
        operations_completed = []
        
        def stress_worker(worker_id: int):
            """å‹åŠ›æµ‹è¯•å·¥ä½œçº¿ç¨‹"""
            try:
                completed_ops = 0
                
                for i in range(operations_per_thread):
                    # éšæœºé€‰æ‹©æ“ä½œç±»å‹
                    operation = random.choice(['get_embeddings', 'cache_operations', 'async_tasks'])
                    
                    if operation == 'get_embeddings':
                        texts = [f"stress_test_{worker_id}_{i}_{j}" for j in range(random.randint(1, 3))]
                        embeddings = service.get_embeddings(texts)
                        assert len(embeddings) == len(texts)
                    
                    elif operation == 'cache_operations':
                        text = f"cache_stress_{worker_id}_{i}"
                        embedding = [random.random() for _ in range(10)]
                        
                        # å†™å…¥ç¼“å­˜
                        cache.put(text, embedding)
                        
                        # è¯»å–ç¼“å­˜
                        cached_embedding = cache.get(text)
                        if cached_embedding:
                            assert len(cached_embedding) == len(embedding)
                    
                    elif operation == 'async_tasks':
                        text = f"async_stress_{worker_id}_{i}"
                        future = service.get_single_embedding_async(text)
                        result = future.result(timeout=10)
                        assert isinstance(result, list)
                    
                    completed_ops += 1
                    
                    # éšæœºå»¶è¿Ÿä»¥æ¨¡æ‹ŸçœŸå®ä½¿ç”¨
                    if random.random() < 0.1:
                        time.sleep(0.01)
                
                operations_completed.append(completed_ops)
                
            except Exception as e:
                errors.append(f"Worker {worker_id} error: {e}")
        
        # å¯åŠ¨å‹åŠ›æµ‹è¯•
        with ThreadPoolExecutor(max_workers=num_threads) as executor:
            futures = []
            for worker_id in range(num_threads):
                futures.append(executor.submit(stress_worker, worker_id))
            
            # ç­‰å¾…æ‰€æœ‰å·¥ä½œçº¿ç¨‹å®Œæˆ
            for future in as_completed(futures):
                future.result()
        
        end_time = time.time()
        total_time = end_time - start_time
        
        # éªŒè¯ç»“æœ
        assert len(errors) == 0, f"Stress test errors: {errors}"
        assert len(operations_completed) == num_threads, "Not all workers completed"
        
        total_operations = sum(operations_completed)
        expected_operations = num_threads * operations_per_thread
        assert total_operations == expected_operations, f"Operations mismatch: {total_operations} vs {expected_operations}"
        
        # æ€§èƒ½ç»Ÿè®¡
        ops_per_second = total_operations / total_time
        logger.info(f"Stress test completed: {total_operations} operations in {total_time:.2f}s ({ops_per_second:.2f} ops/sec)")
        
        # éªŒè¯æœåŠ¡çŠ¶æ€
        service_info = service.get_service_info()
        assert service_info['thread_safe'] == True, "Service should remain thread-safe"
        
        cache_stats = cache.get_stats()
        assert cache_stats is not None, "Cache should provide stats"
    
    def test_resource_cleanup_thread_safety(self):
        """æµ‹è¯•èµ„æºæ¸…ç†çš„çº¿ç¨‹å®‰å…¨æ€§"""
        service = get_thread_safe_embeddings_service()
        
        # åˆ›å»ºå¤§é‡å¼‚æ­¥ä»»åŠ¡
        futures = []
        for i in range(50):
            text = f"cleanup_test_{i}"
            future = service.get_single_embedding_async(text)
            futures.append(future)
        
        # ç­‰å¾…ä¸€åŠä»»åŠ¡å®Œæˆ
        for i in range(0, 25):
            futures[i].result()
        
        # å–æ¶ˆå‰©ä½™ä»»åŠ¡
        cancelled_count = service.cancel_background_tasks()
        assert cancelled_count >= 0, "Should return valid cancellation count"
        
        # ç­‰å¾…ä»»åŠ¡æ¸…ç†
        status = service.wait_for_background_tasks(timeout=10)
        assert status['status'] in ['completed', 'no_active_tasks'], "Tasks should be cleaned up"
        
        # éªŒè¯æœ€ç»ˆçŠ¶æ€
        final_status = service.get_background_task_status()
        assert final_status['active_tasks'] == 0, "No active tasks should remain"


# è¾…åŠ©å‡½æ•°å’Œå¸¸é‡
import logging
logger = logging.getLogger(__name__)


if __name__ == "__main__":
    # ç›´æ¥è¿è¡Œæµ‹è¯•
    test_instance = TestThreadSafetyEmbeddings()
    
    print("Running thread safety tests...")
    
    try:
        test_instance.test_singleton_thread_safety()
        print("âœ“ Singleton thread safety test passed")
        
        test_instance.test_cache_concurrent_access()
        print("âœ“ Cache concurrent access test passed")
        
        test_instance.test_concurrent_embedding_generation()
        print("âœ“ Concurrent embedding generation test passed")
        
        test_instance.test_async_task_management_thread_safety()
        print("âœ“ Async task management thread safety test passed")
        
        test_instance.test_high_concurrency_stress()
        print("âœ“ High concurrency stress test passed")
        
        test_instance.test_resource_cleanup_thread_safety()
        print("âœ“ Resource cleanup thread safety test passed")
        
        print("\nğŸ‰ All thread safety tests passed!")
        
    except Exception as e:
        print(f"\nâŒ Test failed: {e}")
        raise